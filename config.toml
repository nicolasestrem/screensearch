# ScreenSearch Configuration File

[capture]
# Capture interval in milliseconds (default: 3000 = 3 seconds)
interval_ms = 3000

# Enable frame differencing to skip unchanged content
enable_frame_diff = true

# Frame difference threshold (0.0 - 1.0)
# Default 0.006 means skip if < 0.6% change
diff_threshold = 0.006

# Maximum frames to buffer in memory
max_frames_buffer = 30

# Monitor indices to capture (empty = all monitors)
monitor_indices = []

# Whether to include cursor in capture
include_cursor = true

# Whether to draw border around captured window
draw_border = false

[storage]
# Image format: "jpeg" or "png"
format = "jpeg"
# JPEG quality: 1-100 (default: 80)
jpeg_quality = 80
# Max width in pixels (default: 1920). 0 = no resizing
max_width = 1920

[ocr]
# OCR engine: "windows" (Windows OCR API) or "tesseract"
engine = "windows"

# Minimum confidence threshold for storing OCR results (0.0 - 1.0)
# Results below this threshold are discarded
min_confidence = 0.7

# Number of concurrent OCR processing worker threads
worker_threads = 2

# Maximum retry attempts for failed OCR operations
max_retries = 3

# Backoff duration between retries (milliseconds)
retry_backoff_ms = 1000

# Whether to store frames with no text detected
store_empty_frames = true

# Channel buffer size for frame queue
channel_buffer_size = 100

# Enable performance metrics logging
enable_metrics = true

# Metrics reporting interval (seconds)
metrics_interval_secs = 60

[api]
# Host address to bind to
host = "127.0.0.1"

# Port to listen on
port = 3131

# CORS origin (empty = permissive)
cors_origin = ""

[database]
# Database file path
path = "screensearch.db"

# Maximum number of connections in pool
max_connections = 50

# Minimum number of connections in pool
min_connections = 3

# Connection acquire timeout (seconds)
acquire_timeout_secs = 10

# Enable WAL mode for better concurrency
enable_wal = true

# Cache size in KB (negative = KB of memory)
cache_size_kb = -2000

[video]
# Enable video chunk creation
enabled = true

# Chunk duration in seconds
chunk_duration_secs = 300

# Video codec: "h264", "h265", or "vp9"
codec = "h264"

# Video quality (CRF): 0-51 (lower = better quality, larger file)
# Default 23 is good balance
crf = 23

# Frames per second for video
fps = 2

# Maximum video file size in MB (0 = unlimited)
max_file_size_mb = 100

# Delete individual frames after video creation
delete_frames_after_video = false

[cleanup]
# Enable automatic cleanup of old data
enabled = true

# Number of days to retain data (default: 30)
retention_days = 30

# Run cleanup at startup
cleanup_on_startup = true

# Run cleanup periodically (hours between runs)
cleanup_interval_hours = 24

[privacy]
# Privacy: Excluded applications (won't be captured)
# These apps are excluded for privacy/security reasons
excluded_apps = [
    "1Password",
    "KeePass",
    "Bitwarden",
    "LastPass",
    "Dashlane"
]
# Pause capture when screen is locked
pause_on_lock = true

[performance]
# Target FPS for capture (default: 2)
capture_fps = 2.0
# Number of threads for image processing
process_threads = 2
# Compression level (0-9)
compression_level = 6
# Maximum CPU usage percent (0 = unlimited)
max_cpu_percent = 0
# Maximum memory usage in MB (0 = unlimited)
max_memory_mb = 0

[logging]
# Log level: "error", "warn", "info", "debug", "trace"
level = "info"
# Whether to write logs to a file
log_to_file = true
# Log file path
log_file = "screensearch.log"
# Maximum log file size in MB
max_log_size_mb = 100
# Number of rotated log files to keep
log_rotation_count = 5

[embeddings]
# Enable semantic search with embeddings for RAG-enhanced reports
enabled = false

# Embedding model: "local" (bundled multilingual MiniLM) or "api" (use LLM provider)
model = "local"

# Model name for local embeddings
model_name = "paraphrase-multilingual-MiniLM-L12-v2"

# Embedding dimension (384 for MiniLM models)
embedding_dim = 384

# Batch size for background embedding generation
batch_size = 50

# Maximum text length per chunk (tokens)
max_chunk_tokens = 256

# Chunk overlap (tokens) for context preservation
chunk_overlap = 32

# Hybrid search weight (0.0 = all FTS5, 1.0 = all vector)
# Default 0.3 means 70% FTS5, 30% vector similarity
hybrid_search_alpha = 0.3

# Maximum number of relevant chunks to include in LLM context
max_context_chunks = 20
